---
title: "Data Science Context Presentation 2"
author: "Jose Zuniga"
output:
  html_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Presentation Instructions

Make a five-minute presentation on any chosen topic, preferably any topic from the current week's chapter reading of *Data Science for Business*, or another topic that would be of interest to *most*. Do not just summarize the topic, go a little further, such as:

  + Discussing one or more business use cases, or
  + Showing a short example with R code (and perhaps relevant R package(s)), or
  + Providing a curated "learning path" of on-line resources to build further expertise in that topic.

You may also record your presentation instead of presenting in our meetup. Effective data scientists need to be effective presenters, so making a presentation in front of a group is strongly encouraged but not required. In DATA 607, our primary focus is on writing R code related to getting and shaping data in preparation for downstream modeling and presentations. 

***

# Data Mining for Business Intelligence: Concepts, Techniques, and Applications

Author: Galit Shmueli, Nitin R. Patel, and Peter C. Bruce

Date: October 26, 2010

Hardcover: 428 pages

Publisher: Wiley

Language: English

ISBN: 978-0470526828

## Building a Model: Example with Linear Regression (2.6)

### Purpose

To predict the median house value in small Boston area neighborhoods.

### Obtain the Data

```{r}
data(Boston, package="MASS")
```

### Explore, Clean, and Preprocess the Data

```{r}
Boston <- within(Boston, cat.medv <- ifelse(medv >= 30, 1, 0))
names(Boston)
```

  1. CRIM: per capita crime rate by town 
  2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. 
  3. INDUS: proportion of non-retail business acres per town 
  4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) 
  5. NOX: nitric oxides concentration (parts per 10 million) 
  6. RM: average number of rooms per dwelling 
  7. AGE: proportion of owner-occupied units built prior to 1940 
  8. DIS: weighted distances to five Boston employment centers 
  9. RAD: index of accessibility to radial highways 
  10. TAX: full-value property-tax rate per $10,000 
  11. PTRATIO: pupil-teacher ratio by town 
  12. BLACK: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town 
  13. LSTAT: % lower status of the population 
  14. MEDV: Median value of owner-occupied homes in $1000's
  15. CAT.MEDV: High Income dummy variable (= 1 if MEDV $30K or more; 0 otherwise) 
  
```{r}
str(Boston)
summary(Boston)
```

### Reduce the Data and Partition them into Training, Validation, and Test Partitions

No test data in this example. Test data is used when there are multiple models being compared to the validation data in order to reduce bias.
```{r}
n <- nrow(Boston)
set.seed(54)
random <- sample(n, replace=F)
training <- Boston[random[1:(n/2)], ]
validation <- Boston[random[(n/2+1):n], ]
```

### Determine the Data Mining Task

Predict the value of MEDV using the 13 predictor variables.

### Choose the Technique

Multiple Linear Regression

### Use the Algorithm to Perform the Task

Fir the data. Produce a summary. Examine regression residuals. Apply the model to the validation data. Examine correlation. Compare sum of squared errors, mean error, and root-mean-squared (RMS) error of training data and validation data.
```{r}
fit <- lm(medv ~ crim + zn + indus + chas + nox + rm + age + dis + 
            rad + tax + ptratio + black + lstat, data = training)
summary(fit)
training_e <- residuals(fit)
par(mfrow = c(2, 2))
plot(fit)
predictions <- predict(fit, validation)
validation_e <- validation$medv - predictions
cor(validation$medv, predictions)
round(c(sum(training_e^2), mean(training_e), sqrt(mean(training_e^2))), 4)
round(c(sum(validation_e^2), mean(validation_e), sqrt(mean(validation_e^2))), 4)
```

### Interpret the Results

At this point other prediction algorithms are typically tried, variables dropped or added, errors are compared, and then a well-perfuming parsimonious model is chosen.

### Deploy the Model

Median house value in small Boston area neighborhoods is predicted using the model.

#### References

https://archive.ics.uci.edu/ml/datasets/Housing

http://www.slideshare.net/Wyendrila/mini-project-boston-housing-dataset-v1

## Heatmaps: Visualizing Correlations and Missing Values (3.3)

Heatmap of correlation matrix.
```{r}
heatmap(cor(Boston), Rowv=NA, Colv=NA, col = heat.colors(10), scale="none")
```

Heatmap of missing values.
```{r}
x <- matrix(ifelse(is.na(sample(c(NA, 0:10), 1000, T)), 0, 1), 100)
heatmap(x, Rowv=NA, Colv=NA, labRow = "", labCol = "", col = heat.colors(2), scale="column")
```

### References

https://flowingdata.com/2010/01/21/how-to-make-a-heatmap-a-quick-and-easy-solution/

## Specialized Visualizations (3.5)

Visualizing Hierarchical Data (Treemaps).
```{r}
library(treemap)
data(GNI2014)
treemap(GNI2014, index=c("continent", "iso3"), vSize="population", vColor="GNI", type="value")
```

Visualizing Geogrphical Data (Map Charts).
```{r}
library(stringr)
library(XML)
library(maps)
library(httr)
url <- "http://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger"
heritage_parsed <- htmlParse(rawToChar(GET(url)$content))
tables <- readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
danger_table <- danger_table <- tables[[2]]
danger_table <- danger_table[, c(1, 3, 4, 6, 7)]
colnames(danger_table) <- c("name", "locn", "crit", "yins", "yend")
danger_table$crit <- ifelse(str_detect(danger_table$crit, "Natural") == TRUE, "nat", "cult")
danger_table$yins <- as.numeric(danger_table$yins)
yend_clean <- unlist(substr(str_extract_all(danger_table$yend, "[[:digit:]]{4}.$"),1,4))
danger_table$yend <- as.numeric(yend_clean)
reg_y <- "[/][ -]*[[:digit:]]*[.]*[[:digit:]]*[;]"
reg_x <- "[;][ -]*[[:digit:]]*[.]*[[:digit:]]*"
y_coords <- str_extract(danger_table$locn, reg_y)
y_coords <- as.numeric(str_sub(y_coords, 3, -2))
danger_table$y_coords <- y_coords
x_coords <- str_extract(danger_table$locn, reg_x)
x_coords <- as.numeric(str_sub(x_coords, 3, -1))
danger_table$x_coords <- x_coords
danger_table$locn <- NULL
pch <- ifelse(danger_table$crit == "nat", 19, 2)
map("world", col = "darkgrey", lwd = 0.5, mar = c(0.1, 0.1, 0.1, 0.1))
points(danger_table$x_coords, danger_table$y_coords, pch = pch); box()
```

### References 

http://finzi.psych.upenn.edu/library/treemap/html/treemap.html

http://www.stat.wisc.edu/~gvludwig/327-5/maps#/16

Automated Data Collection with R (Pages 1-5)